{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n",
    "import sklearn\n",
    "import sys\n",
    "import gc\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor-positive),axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor-negative),axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0))\n",
    "\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型\n",
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "#print(\"Total Params:\", FRmodel.count_params())\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel)\n",
    "#database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
    "#database[\"andrew\"] = img_to_encoding(\"images/andrew.jpg\", FRmodel)\n",
    "#database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
    "#database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
    "#database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = img_to_encoding(\"images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)\n",
    "database['lisa'] = img_to_encoding('images/lisa.jpg',FRmodel)\n",
    "database['xing'] = img_to_encoding('images/xingtest2.jpg',FRmodel)\n",
    "database['xing1'] = img_to_encoding('images/xing1.jpg',FRmodel)\n",
    "database['xing2'] = img_to_encoding('images/xing2.jpg',FRmodel)\n",
    "#database['xing3'] = img_to_encoding('images/xing3.jpg',FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 96\n",
    "def resize_image(image, height = IMAGE_SIZE, width = IMAGE_SIZE):\n",
    "    top, bottom, left, right = (0, 0, 0, 0)\n",
    "    \n",
    "    #获取图像尺寸\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    #对于长宽不相等的图片，找到最长的一边\n",
    "    longest_edge = max(h, w)    \n",
    "    \n",
    "    #计算短边需要增加多上像素宽度使其与长边等长\n",
    "    if h < longest_edge:\n",
    "        dh = longest_edge - h\n",
    "        top = dh // 2\n",
    "        bottom = dh - top\n",
    "    elif w < longest_edge:\n",
    "        dw = longest_edge - w\n",
    "        left = dw // 2\n",
    "        right = dw - left\n",
    "    else:\n",
    "        pass \n",
    "    \n",
    "    #RGB颜色\n",
    "    BLACK = [0, 0, 0]\n",
    "    \n",
    "    #给图像增加边界，是图片长、宽等长，cv2.BORDER_CONSTANT指定边界颜色由value指定\n",
    "    constant = cv2.copyMakeBorder(image, top , bottom, left, right, cv2.BORDER_CONSTANT, value = BLACK)\n",
    "    \n",
    "    #调整图像大小并返回\n",
    "    return cv2.resize(constant, (height, width))\n",
    "\n",
    "def who_is_it(image, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the happy house by finding who is the person on the image_path image.\n",
    "    \n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    database -- database containing image encodings along with the name of the person on the image\n",
    "    model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
    "    identity -- string, the name prediction for the person on image_path\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above\n",
    "    encoding = image_to_encoding(image,model)\n",
    "    \n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    \n",
    "    # Initialize \"min_dist\" to a large value\n",
    "    min_dist = 100\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        # Compute L2 distance between the target \"encoding\" and the current \"emb\" from the database\n",
    "        dist = np.linalg.norm(encoding-db_enc)\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name\n",
    "        if dist<min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "\n",
    "    '''\n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "    '''    \n",
    "    return min_dist, identity\n",
    "\n",
    "def findNearestClassForImage(face_descriptor, faceLabel):\n",
    "    temp =  face_descriptor - data\n",
    "    e = np.linalg.norm(temp,axis=1,keepdims=True)\n",
    "    min_distance = e.min() \n",
    "    #print('distance: ', min_distance)\n",
    "    if min_distance > threshold:\n",
    "        return 'other'\n",
    "    index = np.argmin(e)\n",
    "    return faceLabel[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image emcodding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = 'imgs/'                                                                           #图像的目录\n",
    "data = np.zeros((1,128))                                                                            #定义一个128维的空向量data\n",
    "label = []                                                                                          #定义空的list存放人脸的标签\n",
    "\n",
    "for file in os.listdir(imagePath):                                                                  #开始一张一张索引目录中的图像\n",
    "    if '.jpg' in file or '.png' in file:\n",
    "        fileName = file\n",
    "        labelName = file.split('_')[0]                                                              #获取标签名\n",
    "        print('current image: ', file)\n",
    "        print('current label: ', labelName)\n",
    "        \n",
    "        img = cv2.imread(imagePath + file)                                                          #使用opencv读取图像数据\n",
    "        if img.shape[0]*img.shape[1] > 500000:                                                      #如果图太大的话需要压缩，这里像素的阈值可以自己设置\n",
    "            img = cv2.resize(img, (0,0), fx=0.5, fy=0.5)\n",
    "            \n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)#将图片转化成灰度\n",
    "\n",
    "        face_cascade = cv2.CascadeClassifier(\"D:\\\\WM\\\\AI learning\\\\Ng - Deep Learning\\\\course4\\\\face recognistion\\\\haarcascade_frontalface_alt2.xml\")\n",
    "        #face_cascade.load('/haarcascade_frontalface_alt2.xml')#一定要告诉编译器文件所在的具体位置\n",
    "        #'''此文件是opencv的haar人脸特征分类器'''\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.2,  minNeighbors = 3, minSize = (32, 32))\n",
    "        #print(faces)\n",
    "        #image_set=[]\n",
    "        for (x,y,w,h) in faces: \n",
    "            \n",
    "        #dets = detector(img, 1)                                                                     #使用检测算子检测人脸，返回的是所有的检测到的人脸区域\n",
    "        #for k, d in enumerate(dets):\n",
    "            image = img[y - 10: y + h + 10, x - 10: x + w + 10]\n",
    "            image = resize_image(image)\n",
    "            embeddings = image_to_encoding(image, FRmodel)                                                                   #获取landmark\n",
    "            #faceArray = np.array(face_descriptor).reshape((1, 128))                                 #转换成numpy中的数据结构\n",
    "            data = np.concatenate((data, embeddings))                                                #拼接到事先准备好的data当中去\n",
    "            label.append(labelName)                                                                 #保存标签\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)       #显示人脸区域\n",
    "            \n",
    "        cv2.namedWindow('img',1)#O表示显示窗口可以随意手动调节，1\n",
    "        cv2.imshow('img',img)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "data = data[1:, :]                                                                                  #因为data的第一行是空的128维向量，所以实际存储的时候从第二行开始\n",
    "np.savetxt('faceData.txt', data, fmt='%f')                                                          #保存人脸特征向量合成的矩阵到本地\n",
    "\n",
    "labelFile=open('label.txt','w')                                      \n",
    "json.dump(label, labelFile)                                                                         #使用json保存list到本地\n",
    "labelFile.close()\n",
    "\n",
    "cv2.destroyAllWindows()                                                                             #关闭所有的窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# camera capture photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your name: Travis_li\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "# save the photos\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # open data and label file\n",
    "    labelFile=open('label.txt','r')\n",
    "    label = json.load(labelFile)                                                   #载入本地人脸库的标签\n",
    "    labelFile.close()   \n",
    "    data = np.loadtxt('faceData.txt',dtype=float)  \n",
    "    \n",
    "    # threshold of recognising photo\n",
    "    threshold = 0.54\n",
    "    # later save into label name\n",
    "    name = input('Please input your name: ')\n",
    "   \n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX           \n",
    "    #框住人脸的矩形边框颜色       \n",
    "    color = (0, 255, 0)\n",
    "    \n",
    "    #count pic, if test pics\n",
    "    cnt_p = 0 \n",
    "    \n",
    "    #捕获指定摄像头的实时视频流\n",
    "    cap = cv2.VideoCapture(0)#int(sys.argv[1]))\n",
    "    \n",
    "    #人脸识别分类器本地存储路径\n",
    "    cascade_path = 'D:\\\\WM\\\\AI learning\\\\Ng - Deep Learning\\\\course4\\\\face recognistion\\\\haarcascade_frontalface_alt2.xml'    \n",
    "    #D:\\\\WM\\\\AI learning\\\\Ng - Deep Learning\\\\course4\\\\face recognistion\\\\haarcascade_frontalface_alt2.xml\n",
    "\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()   #读取一帧视频\n",
    "        \n",
    "        # kk is the return value of cv2.waitKey; the value is what user input\n",
    "        kk = cv2.waitKey(1)\n",
    "\n",
    "        #图像灰化，降低计算复杂度\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #使用人脸识别分类器，读入分类器\n",
    "        cascade = cv2.CascadeClassifier(cascade_path)                \n",
    "\n",
    "        #利用分类器识别出哪个区域为人脸\n",
    "        faceRects = cascade.detectMultiScale(frame_gray, scaleFactor = 1.2, minNeighbors = 3, minSize = (32, 32))        \n",
    "        if len(faceRects) > 0:                 \n",
    "            for faceRect in faceRects: \n",
    "                x, y, w, h = faceRect\n",
    "                \n",
    "                # if user input 's' ,then save pic\n",
    "                if kk == ord('s'):\n",
    "               \n",
    "                    #截取脸部图像提交给模型识别这是谁\n",
    "                    image = frame[y: y + h-5, x+10 : x + w -20]\n",
    "                    image = resize_image(image)\n",
    "                    embeddings = image_to_encoding(image, FRmodel) \n",
    "                #save image matrix and label \n",
    "                    data = np.concatenate((data, embeddings))                                                \n",
    "                    label.append(name) \n",
    "                    \n",
    "                    '''\n",
    "                    # test photo size\n",
    "                    path_make_dir = \"imgs/img/\"\n",
    "                    cnt_p += 1\n",
    "                    cv2.imwrite(path_make_dir + \"/img_face_\" + str(cnt_p) + \".jpg\", image)\n",
    "                    print(\"write：\", str(path_make_dir) + \"/img_face_\" + str(cnt_p) + \".jpg\")\n",
    "                    '''\n",
    "                                                    \n",
    "                cv2.rectangle(frame, (x - 10, y - 10), (x + w +10, y + h +10), color, thickness = 2)\n",
    "                cv2.putText(frame, \"Faces: \" + str(len(faceRects)), (20, 100), font, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "                # 添加说明\n",
    "                cv2.putText(frame, \"Face Register\", (20, 40), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                #cv2.putText(im_rd, \"N: New face folder\", (20, 350), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, \"S: Save face\", (20, 400), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, \"Q: Quit\", (20, 450), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # 按下 'q' 键退出\n",
    "        if kk & 0xFF== ord('q'):\n",
    "            break    \n",
    "\n",
    "                            \n",
    "        cv2.imshow(\"Identify you\", frame)\n",
    "        '''        \n",
    "        #等待10毫秒看是否有按键输入\n",
    "        k = cv2.waitKey(10)\n",
    "        #如果输入q则退出循环\n",
    "        if k & 0xFF == ord('q'):\n",
    "            break\n",
    "        '''  \n",
    "    np.savetxt('faceData.txt', data, fmt='%f')                                                          #保存人脸特征向量合成的矩阵到本地\n",
    "\n",
    "    labelFile=open('label.txt','w')                                      \n",
    "    json.dump(label, labelFile)                                                                         #使用json保存list到本地\n",
    "    labelFile.close()\n",
    "    #释放摄像头并销毁所有窗口\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, (35, 128))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label), data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aaron',\n",
       " 'Aaron',\n",
       " 'Bank19',\n",
       " 'Bella',\n",
       " 'dad',\n",
       " 'dad',\n",
       " 'dad',\n",
       " 'Emma',\n",
       " 'lisa',\n",
       " 'lisa',\n",
       " 'lisa',\n",
       " 'lisa',\n",
       " 'mum',\n",
       " 'mum',\n",
       " 'mum',\n",
       " 'Robert',\n",
       " 'xing18',\n",
       " 'xing18',\n",
       " 'xing18',\n",
       " 'Yawei',\n",
       " 'tiancai',\n",
       " 'tiancai',\n",
       " 'tiancai',\n",
       " 'tiancai',\n",
       " 'tiancai',\n",
       " 'cen',\n",
       " 'cen',\n",
       " 'cen',\n",
       " 'cen',\n",
       " 'Travis_li',\n",
       " 'Travis_li',\n",
       " 'Travis_li',\n",
       " 'Travis_li',\n",
       " 'Travis_li',\n",
       " 'Travis_li']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "# recognize\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage:%s camera_id\\r\\n\" % (sys.argv[0]))\n",
    "        sys.exit(0)\n",
    "    '''   \n",
    "    labelFile=open('label.txt','r')\n",
    "    label = json.load(labelFile)                                                   #载入本地人脸库的标签\n",
    "    labelFile.close()\n",
    "    threshold = 0.54\n",
    "    data = np.loadtxt('faceData.txt',dtype=float)  \n",
    "    #model = Model()\n",
    "    #model.load_model(file_path = './model/me.face.model.h5')    \n",
    "               \n",
    "    #框住人脸的矩形边框颜色       \n",
    "    color = (0, 255, 0)\n",
    "    \n",
    "    #捕获指定摄像头的实时视频流\n",
    "    cap = cv2.VideoCapture(0)#int(sys.argv[1]))\n",
    "    \n",
    "    #人脸识别分类器本地存储路径\n",
    "    \n",
    "    cascade_path = 'D:\\\\WM\\\\AI learning\\\\Ng - Deep Learning\\\\course4\\\\face recognistion\\\\haarcascade_frontalface_alt2.xml'\n",
    "    #D:\\\\WM\\\\AI learning\\\\Ng - Deep Learning\\\\course4\\\\face recognistion\\\\haarcascade_frontalface_alt2.xml\n",
    "    #循环检测识别人脸\n",
    "    #while(cap.isOpened()):  # check !\n",
    "    # capture frame-by-frame\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()   #读取一帧视频\n",
    "        \n",
    "        #if ret: # check ! (some webcam's need a \"warmup\")\n",
    "        # our operation on frame come here\n",
    "        #图像灰化，降低计算复杂度\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #使用人脸识别分类器，读入分类器\n",
    "        #cascade = cv2.CascadeClassifier(\"D:\\\\WM\\\\AI learning\\\\Ng - Deep Learning\\\\course4\\\\face recognistion\\\\haarcascade_frontalface_alt2.xml\")\n",
    "        cascade = cv2.CascadeClassifier(cascade_path)                \n",
    "\n",
    "        #利用分类器识别出哪个区域为人脸\n",
    "        faceRects = cascade.detectMultiScale(frame_gray, scaleFactor = 1.2, minNeighbors = 3, minSize = (32, 32))        \n",
    "        if len(faceRects) > 0:                 \n",
    "            for faceRect in faceRects: \n",
    "                x, y, w, h = faceRect\n",
    "                \n",
    "                #截取脸部图像提交给模型识别这是谁\n",
    "                image = frame[y - 10: y + h + 10, x - 10: x + w + 10]\n",
    "                image = resize_image(image)\n",
    "                #print('o: ',frame.shape)\n",
    "                #print('now: ',image.shape)\n",
    "                #_,identity = who_is_it(image, database, FRmodel)\n",
    "                embeddings = image_to_encoding(image, FRmodel) \n",
    "                class_pre = findNearestClassForImage(embeddings, label)  \n",
    "                \n",
    "                \n",
    "                #如果是“我”\n",
    "                #if faceID == 0:                                                        \n",
    "                cv2.rectangle(frame, (x - 10, y - 10), (x + w + 10, y + h + 10), color, thickness = 2)\n",
    "                    \n",
    "                #文字提示是谁\n",
    "                cv2.putText(frame,class_pre, \n",
    "                            (x + 30, y + 30),                      #坐标\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,              #字体\n",
    "                            1,                                     #字号\n",
    "                            (255,0,255),                           #颜色\n",
    "                            2)                                     #字的线宽\n",
    "\n",
    "                            \n",
    "        cv2.imshow(\"Identify you\", frame)\n",
    "                  \n",
    "        #等待10毫秒看是否有按键输入\n",
    "        k = cv2.waitKey(10)\n",
    "        #如果输入q则退出循环\n",
    "        if k & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    #释放摄像头并销毁所有窗口\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('imgs/Bank_19.jpg',1)#读取一张图片\n",
    "#plt.imshow(img)\n",
    "#img = resize_image(img)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)#将图片转化成灰度\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"D:\\\\WM\\\\AI learning\\\\Ng - Deep Learning\\\\course4\\\\face recognistion\\\\haarcascade_frontalface_alt2.xml\")\n",
    "#face_cascade.load('/haarcascade_frontalface_alt2.xml')#一定要告诉编译器文件所在的具体位置\n",
    "#'''此文件是opencv的haar人脸特征分类器'''\n",
    "faces = face_cascade.detectMultiScale(gray, 1.2,  minNeighbors =2, minSize = (32, 32))\n",
    "print(faces)\n",
    "image_set=[]\n",
    "for (x,y,w,h) in faces:\n",
    "    image = img[y - 10: y + h + 10, x - 10: x + w + 10]\n",
    "    image_set.append(resize_image(image))\n",
    "    #print(i)\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "\n",
    "\n",
    "cv2.namedWindow('img',0)#O表示显示窗口可以随意手动调节，1\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "for i in range(len(image_set)):\n",
    "    plt.imshow(image_set[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,d in enumerate(faces):\n",
    "    print(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition(img):\n",
    "    dets = detector(img, 1)\n",
    "    for k, d in enumerate(dets):\n",
    "        \n",
    "        print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "            k, d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom()))\n",
    "        rec = dlib.rectangle(d.rect.left(),d.rect.top(),d.rect.right(),d.rect.bottom())\n",
    "        print(rec.left(),rec.top(),rec.right(),rec.bottom())\n",
    "        shape = sp(img, rec)\n",
    "        face_descriptor = facerec.compute_face_descriptor(img, shape)        \n",
    "        \n",
    "        class_pre = findNearestClassForImage(face_descriptor, label)\n",
    "        print(class_pre)\n",
    "        cv2.rectangle(img, (rec.left(), rec.top()+10), (rec.right(), rec.bottom()), (0, 255, 0), 2)\n",
    "        cv2.putText(img, class_pre , (rec.left(),rec.top()), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):  # check !\n",
    "    # capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret: # check ! (some webcam's need a \"warmup\")\n",
    "        # our operation on frame come here\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame', gray)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# When everything is done release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Dlib 预测器\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "name = input('what\\'s your name? ')\n",
    "# 创建 cv2 摄像头对象\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# cap.set(propId, value)\n",
    "# 设置视频参数，propId 设置的视频参数，value 设置的参数值\n",
    "cap.set(3, 480)\n",
    "\n",
    "# 截图 screenshoot 的计数器\n",
    "cnt_ss = 0\n",
    "\n",
    "# 人脸截图的计数器\n",
    "cnt_p = 0\n",
    "\n",
    "# 存储人脸的文件夹\n",
    "current_face_dir = 0\n",
    "\n",
    "# 保存\n",
    "path_make_dir = \"imgs/img/\"\n",
    "\n",
    "path_csv = \"data/csvs_from_camera/\"\n",
    "\n",
    "'''\n",
    "# clear the old folders at first\n",
    "def pre_clear():\n",
    "    folders_rd = os.listdir(path_make_dir)\n",
    "    for i in range(len(folders_rd)):\n",
    "        shutil.rmtree(path_make_dir+folders_rd[i])\n",
    "\n",
    "    csv_rd = os.listdir(path_csv)\n",
    "    for i in range(len(csv_rd)):\n",
    "        os.remove(path_csv+csv_rd[i])\n",
    "\n",
    "\n",
    "# clear the exist folders of faces and csv\n",
    "pre_clear()\n",
    "'''\n",
    "\n",
    "# 人脸种类数目的计数器\n",
    "person_cnt = 0\n",
    "\n",
    "# cap.isOpened（） 返回 true/false 检查初始化是否成功\n",
    "while cap.isOpened():\n",
    "\n",
    "    # cap.read()\n",
    "    # 返回两个值：\n",
    "    #    一个布尔值 true/false，用来判断读取视频是否成功/是否到视频末尾\n",
    "    #    图像对象，图像的三维矩阵q\n",
    "    flag, im_rd = cap.read()\n",
    "\n",
    "    # 每帧数据延时 1ms，延时为 0 读取的是静态帧\n",
    "    kk = cv2.waitKey(1)\n",
    "\n",
    "    # 取灰度\n",
    "    img_gray = cv2.cvtColor(im_rd, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # 人脸数 rects\n",
    "    rects = detector(img_gray, 0)\n",
    "\n",
    "    # print(len(rects))q\n",
    "\n",
    "    # 待会要写的字体\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "\n",
    "    # 按下 'n' 新建存储人脸的文件夹\n",
    "    if kk == ord('n'):\n",
    "        person_cnt += 1\n",
    "        # current_face_dir = path_make_dir + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "        current_face_dir = path_make_dir + \"name_\" + str(person_cnt)\n",
    "        print('\\n')\n",
    "        for dirs in (os.listdir(path_make_dir)):\n",
    "            if current_face_dir == path_make_dir + dirs:\n",
    "                shutil.rmtree(current_face_dir)\n",
    "                print(\"删除旧的文件夹:\", current_face_dir)\n",
    "        os.makedirs(current_face_dir)\n",
    "        print(\"新建的人脸文件夹: \", current_face_dir)\n",
    "\n",
    "        # 将人脸计数器清零\n",
    "        cnt_p = 0\n",
    "\n",
    "    if len(rects) != 0:\n",
    "        # 检测到人脸\n",
    "\n",
    "        # 矩形框\n",
    "        for k, d in enumerate(rects):\n",
    "\n",
    "            # 计算矩形大小\n",
    "            # (x,y), (宽度width, 高度height)\n",
    "            pos_start = tuple([d.left(), d.top()])\n",
    "            pos_end = tuple([d.right(), d.bottom()])\n",
    "\n",
    "            # 计算矩形框大小\n",
    "            height = d.bottom() - d.top()\n",
    "            width = d.right() - d.left()\n",
    "\n",
    "            # 根据人脸大小生成空的图像\n",
    "            cv2.rectangle(im_rd, tuple([d.left(), d.top()]), tuple([d.right(), d.bottom()]), (0, 255, 255), 2)\n",
    "            im_blank = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "            # 按下 's' 保存摄像头中的人脸到本地\n",
    "            if kk == ord('s'):\n",
    "                cnt_p += 1\n",
    "                for ii in range(height):\n",
    "                    for jj in range(width):\n",
    "                        im_blank[ii][jj] = im_rd[d.top() + ii][d.left() + jj]\n",
    "                cv2.imwrite(current_face_dir + \"/img_face_\" + str(cnt_p) + \".jpg\", im_blank)\n",
    "                print(\"写入本地：\", str(current_face_dir) + \"/img_face_\" + str(cnt_p) + \".jpg\")\n",
    "\n",
    "        # 显示人脸数\n",
    "    cv2.putText(im_rd, \"Faces: \" + str(len(rects)), (20, 100), font, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # 添加说明\n",
    "    cv2.putText(im_rd, \"Face Register\", (20, 40), font, 1, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    #cv2.putText(im_rd, \"N: New face folder\", (20, 350), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(im_rd, \"S: Save face\", (20, 400), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(im_rd, \"Q: Quit\", (20, 450), font, 0.8, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    # 按下 'q' 键退出\n",
    "    if kk == ord('q'):\n",
    "        break\n",
    "\n",
    "    # 窗口显示\n",
    "    # cv2.namedWindow(\"camera\", 0) # 如果需要摄像头窗口大小可调\n",
    "    cv2.imshow(\"camera\", im_rd)\n",
    "\n",
    "# 释放摄像头\n",
    "cap.release()\n",
    "\n",
    "# 删除建立的窗口\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
